# -*- coding: utf-8 -*-
"""CV_archi_0.3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gr39W8G0bbFAYmhD0iv6oi0xzx68xR48
"""

import torch
from torch import nn
from transformers import CLIPProcessor
import torch.nn.functional as F
import os
from torch.optim import AdamW
from torch.utils.data import DataLoader
import time
from accelerate import Accelerator
import glob
from safetensors.torch import load_file

from coseg.model.model import CoSeg
from coseg.model.lang_model import CLIPLang
from coseg.utils import COCOStuffDataset, collate_fn_factory, WarmupCosineLR

import wandb

os.environ["TOKENIZERS_PARALLELISM"] = "false"

src_dir = "/home/research/jianhong.t/OpenVocab_Seg_with_AutoRegres/src/"
dataset_dir = "/scratch/t.tovi/datasets/"
image_dir = "coco-stuff/COCO_stuff_images/train2017/"
annotation_dir = "COCO_stuff_annotations/train2017/"


def dice_loss(y_true, y_pred):
    numerator = 2 * torch.sum(y_true * y_pred)
    denominator = torch.sum(y_true + y_pred)
    return 1 - numerator / denominator

def train():
    # Init accelerator
    accelerator = Accelerator()
    device = accelerator.device

    # Create dataset object
    data = COCOStuffDataset(
        dataset_dir+image_dir,
        dataset_dir+annotation_dir,
        img_size=224
    )

    lang_model = CLIPLang()
    lang_model.eval()
    processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch16")

    # Get loss query table
    label_indices = list(data.digit_to_object_mapping.keys())
    label_text = ["a photo of " + data.digit_to_object_mapping[each] for each in label_indices]
    inputs = processor(label_text, padding=True, return_tensors='pt')

    with torch.no_grad():
        label_embeddings = lang_model(**inputs)["text_embeds"]
    label_embeddings.requires_grad_(False)

    # Get the collate function
    collate_fn = collate_fn_factory(processor)

    # Create batch data loader
    data_loader = DataLoader(data, batch_size=32, collate_fn=collate_fn, num_workers=4, shuffle=True)

    # Initialize the model
    model = CoSeg(d_reduce=128, nencoder=4, ndecoder=4, lang_model="xatten") 

    if glob.glob("/scratch/t.tovi/models/autoseg_xatten"):
        model.load_state_dict(load_file("/scratch/t.tovi/models/autoseg_xatten/model.safetensors"))
    
    m = nn.Sigmoid()
    model.to(device)

    # Define training parameters
    lr = 1e-4
    alpha = 0.08
    beta = 0.18
    temperature = 0.08
    num_epochs = 100

    # Optimizer
    optim = AdamW(
        [p for p in model.parameters() if p.requires_grad],
        lr = lr,
        weight_decay = 1e-4
    )

    iterations = num_epochs * len(data_loader)
    print(f"There are in total {iterations} iterations")
    scheduler = WarmupCosineLR(optim, warmup_epochs=int(0.1*iterations), total_epochs=iterations, eta_min=1e-7)

    # Loss
    mask_objective = nn.BCEWithLogitsLoss()
    mask_objective2 = dice_loss
    lang_objective = nn.CrossEntropyLoss()

    # Use accelerator instead
    model, optim, data_loader, scheduler = accelerator.prepare(model, optim, data_loader, scheduler)

    """## Train"""
    wandb.init(project="coseg", name=f"legacy_xatten_{lr}_{iterations}")
    label_embeddings = label_embeddings.to(device)
    label_embeddings = F.normalize(label_embeddings, dim=-1)

    count = 0
    batch_loss = 0
    batch_l1 = 0
    batch_l2 = 0
    batch_l3 = 0
    current = time.time()
    for e in range(num_epochs):
        for batch in data_loader:
            # Prepare data
            pixel_values = batch['pixel_values'].to(device)
            masks = batch['masks'].to(device)
            ids = batch['ids'].to(device)

            mask_logits, pred_embeddings = model(pixel_values)
            pred_embeddings = F.normalize(pred_embeddings, dim=-1)
            label_logits = pred_embeddings @ label_embeddings.T / temperature

            # Compute loss
            mask_prob = m(mask_logits)
            l1 = mask_objective(mask_logits, masks)
            l2 = alpha * lang_objective(label_logits.permute(0, 2, 1), ids)
            l3 = beta * mask_objective2(masks, mask_prob)

            # Total loss
            loss = l1 + l2 + l3

            # Backward
            accelerator.backward(loss)

            # CLIP gradient norm
            accelerator.clip_grad_norm_(model.parameters(), 1.0)

            # Gradient update
            optim.step()
            optim.zero_grad()

            batch_loss += loss.detach().cpu().item()
            batch_l1 += l1.detach().cpu().item()
            batch_l2 += l2.detach().cpu().item()
            batch_l3 += l3.detach().cpu().item()

            if (count+1) % 64 == 0:
                elapsed = time.time() - current
                info = {
                    "Epoch": e,
                    "Step": count,
                    "Total loss": batch_loss / 64,
                    "Mask loss": batch_l1 / 64,
                    "Lang loss": batch_l2 / 64,
                    "Dice loss": batch_l3 / 64,
                    "Lr": scheduler.get_last_lr()[0]
                }
                finish_time = int(elapsed * (iterations - count) / 64)
                fhr = finish_time // 3600
                fmin = (finish_time % 3600) // 60
                print(f"Iter: {count} Average batch loss: {batch_loss / 64} ETC: {fhr}:{fmin}", flush=True)
                batch_loss = 0
                batch_l1 = 0
                batch_l2 = 0
                batch_l3 = 0
                current = time.time()
                wandb.log(info)

            count += 1
            scheduler.step()

        print("One training epoch done")

    accelerator.wait_for_everyone()
    model = accelerator.unwrap_model(model)
    accelerator.save_model(model, "/scratch/t.tovi/models/autoseg_xatten")
        #torch.save(model.state_dict(), "/scratch/t.tovi/models/autoseg_legacy_xatten.pth")

if __name__ == "__main__":
    train()